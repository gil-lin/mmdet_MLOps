
###############################################################
#Config Description:
#map : out_of_lable to vehicle
#leaving us with 4 categories [person, vehicle, two-wheeled, dilemma-zone]
#treating only dilemma-zone as iscrowd
#filtering dilemma_zone from class ClassBalancedDataset
#modifying self.CLASSES: [person, vehicle, two-wheeled]
#modifyed num_classes: 3
################################################################

checkpoint_config:
  interval: 1

custom_hooks:
  - type: NumClassCheckHook

dist_params:
  backend: nccl

log_level: INFO

load_from: ~
resume_from: ~
categories: !!python/tuple [person, vehicle, two-wheeled]

# disable opencv multithreading to avoid system being overloaded
opencv_num_threads: 0
# set multi-process start method as `fork` to speed up the training
mp_start_method: fork

work_dir: ~
workflow: [!!python/tuple [train, 1], !!python/tuple [val, 1]]  # 1 epoch for training and 1 epoch for validation

log_config:
    interval: 50
    hooks:
      - type: TextLoggerHook
      - type: AllegroAiLLoggerHook

# model settings
model:
  type: YOLOV3
  backbone:
      type: Darknet
      depth: 53
      out_indices: !!python/tuple [2, 3, 4, 5]
      init_cfg: ~
  neck:
    type: YOLOV3Neck
    num_scales: 4
    in_channels: [1024, 512, 256, 128]
    out_channels: [512, 256, 128, 64]
  bbox_head:
    type: YOLOV3Head
    num_classes: 3
    in_channels: [512, 256, 128, 64]
    out_channels: [1024, 512, 256, 128]
    anchor_generator:
      type: YOLOAnchorGenerator
      base_sizes:
        - [!!python/tuple [43, 99], !!python/tuple [99, 50], !!python/tuple [56, 142], !!python/tuple [165, 92]]
        - [!!python/tuple [47, 21], !!python/tuple [49, 36], !!python/tuple [27, 69], !!python/tuple [77, 32]]
        - [!!python/tuple [29, 14], !!python/tuple [16, 37], !!python/tuple [29, 27], !!python/tuple [20, 49]]
        - [!!python/tuple [13, 12], !!python/tuple [9, 21], !!python/tuple [12, 29], !!python/tuple [19, 19]]
      strides: [32, 16, 8, 4]
    bbox_coder:
      type: YOLOBBoxCoder
    featmap_strides: [32, 16, 8, 4]
    loss_cls:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 1.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_conf:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 1.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_xy:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 2.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_wh:
      type: MSELoss
      loss_weight: 2.0
      reduction: sum
  train_cfg:
    assigner:
      type: GridAssigner
      pos_iou_thr: 0.5
      neg_iou_thr: 0.5
      min_pos_iou: 0
  test_cfg:
    nms_pre: 1000
    min_bbox_size: 0
    score_thr: 0.05
    conf_thr: 0.005
    nms:
      type: nms
      iou_threshold: 0.45
    max_per_img: 100

data:
  samples_per_gpu: 4
  workers_per_gpu: 4
  train:
    type: ClassBalancedDataset  # 'RepeatDataset',  # use RepeatDataset to speed up training
    oversample_thr: 0.5  # number of minor category annotations / total number of images # times: 1,
    dataset:
      type: AllegroDataset
      CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
      filter_empty_gt: True
      remote:
        s3_root_dir: ~
        skip_local_run: False
        queue_name: scaler-styletransfer-g2g-rgbmwir
        prefetch: True
        url: ann_file_train_val_overfit_1000.json
      args:
        read_from_file:
          read: True
          path_name: ann_file_train_val_overfit_1000.json
        to_serialize:
          save: True
          path_name: ann_file_train_val_overfit_1000.json
        max_frame_size: 32
        filter_empty_gt: True
        data_root: '.'
        workflow: ~
      dataview_cfg:
        queries:
          dataset_name: Style_Transfer
          version_name: version_2_mwir_train
          weight: 1
        name: train
        max_num_frames: ~ # can be used for overfitting tests
        frame_type: rgb
        cat_mapping: {"*": {out_of_lable: vehicle}}
        special_cat_mapping:
          ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
          ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
          negative: { "*": ~ }
        predefined_label_enums: ~
      pipeline:
        - type: LoadImageFromFile
          to_float32: True
          color_type: color # [color, grayscale, unchanged]
          channel_order: bgr  # if 'grayscale' channel_order doesn't matter
        - type: LoadAnnotations
          with_bbox: True
        - type: Expand
          mean: [0., 0., 0.]
          to_rgb: False
          ratio_range: !!python/tuple [1, 2]
        - type: MinIoURandomCrop
          min_ious: !!python/tuple [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
          min_crop_size: 0.3
        - type: Resize
          img_scale:
            - !!python/tuple [320, 320]
            - !!python/tuple [608, 608]
          multiscale_mode: range
          keep_ratio: True
        - type: RandomFlip
          flip_ratio: 0.5
#        - type: PhotoMetricDistortion
        - type: Normalize
          mean: [0., 0., 0.]
          std: [255., 255., 255.]
          to_rgb: False
        - type: Pad
          size_divisor: 32
        - type: DefaultFormatBundle
        - type: Collect
          keys:
            - img
            - gt_bboxes
            - gt_labels
  val:
    type: AllegroDataset
    CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
    remote:
      s3_root_dir: ~
      skip_local_run: False
      queue_name: scaler-styletransfer-g2g-rgbmwir
      prefetch: True
      url: ann_file_train_val_overfit_1000.json
    args:
      read_from_file:
        read: True
        path_name: ann_file_train_val_overfit_1000.json
      to_serialize:
        save: False
        path_name: ann_file_train_val_overfit_1000.json
      max_frame_size: 32
      filter_empty_gt: True
      data_root: '.'
      workflow: ~
    dataview_cfg:
      queries:
        dataset_name: Style_Transfer
        version_name: version_2_mwir_val
        weight: 1
      name: val
      max_num_frames: ~
      frame_type: mwir
      cat_mapping: {"*": {out_of_lable: vehicle}} # Changing name of class as defined in the dataset to fit your models categories
      special_cat_mapping:
        ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
        ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
        negative: { "*": ~ }
      predefined_label_enums: ~
    pipeline:
      - type: LoadImageFromFile
        color_type: color
      - type: MultiScaleFlipAug
        img_scale: !!python/tuple [608, 608]
        flip: False
        transforms:
          - type: Resize
            keep_ratio: True
          - type: RandomFlip
          - type: Normalize
            mean: [0., 0., 0.]
            std: [255., 255., 255.]
            to_rgb: False
          - type: Pad
            size_divisor: 32
          - type: ImageToTensor
            keys:
              - img
          - type: Collect
            keys:
              - img
  test:
    type: AllegroDataset
    CLASSES: !!python/tuple [ person, vehicle, two-wheeled, out_of_lable, dilemma_zone ]
    remote:
      s3_root_dir: ~
      skip_local_run: False
      queue_name: scaler-styletransfer-g2g-rgbmwir
      prefetch: True
      url: ann_file_train_val_overfit_1000.json
    args:
      read_from_file:
        read: True
        path_name: ann_file_train_val_overfit_1000.json
      to_serialize:
        save: False
        path_name: ann_file_train_val_overfit_1000.json
      max_frame_size: 32
      filter_empty_gt: True
      data_root: '.'
      workflow: ~
    dataview_cfg:
      queries:
        dataset_name: Style_Transfer
        version_name: version_2_mwir_val
        weight: 1
      name: val
      max_num_frames: ~
      frame_type: mwir
      cat_mapping: { "*": { out_of_lable: vehicle } } # Changing name of class as defined in the dataset to fit your models categories
      special_cat_mapping:
        ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
        ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
        negative: { "*": ~ }
      predefined_label_enums: ~
    pipeline:
      - type: LoadImageFromFile
        color_type: color
      - type: MultiScaleFlipAug
        img_scale: !!python/tuple [ 608, 608 ]
        flip: False
        transforms:
          - type: Resize
            keep_ratio: True
          - type: RandomFlip
          - type: Normalize
            mean: [ 0., 0., 0. ]
            std: [ 255., 255., 255. ]
            to_rgb: False
          - type: Pad
            size_divisor: 32
          - type: ImageToTensor
            keys:
              - img
          - type: Collect
            keys:
              - img
optimizer:
  type: SGD
  lr: 0.001 # start
  momentum: 0.9
  weight_decay: 0.0005

#optimizer:
#  type: AdamW
#  lr: 0.0001
#  weight_decay: 0.05
#  paramwise_cfg:
#    norm_decay_mult: 0.
#    bypass_duplicate: True

optimizer_config:
  grad_clip:
    max_norm: 35
    norm_type: 2

lr_config:
    policy: CosineAnnealing
    warmup: linear
    warmup_iters: 4000
    warmup_ratio: 0.1
    min_lr_ratio: 1.e-5
    warmup_by_epoch: False

#lr_config:
#  policy: step
#  warmup: linear
#  warmup_iters: 4000
#  warmup_ratio: 0.0001
#  step: [24, 28]

# runtime settings
runner:
  type: EpochBasedRunner
  max_epochs: 100

# evaluate the model every "interval=1" epochs.
evaluation:
  interval: 1
  save_best: bbox_mAP
  rule: greater
  metric:
   - bbox
  classwise: False

find_unused_parameters: True
auto_resume: False
gpu_ids:
  - 1

auto_scale_lr:
  enable: False
  base_batch_size: 64
