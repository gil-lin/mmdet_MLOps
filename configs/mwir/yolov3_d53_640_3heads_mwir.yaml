
###############################################################
#Config Description:
#map : out_of_lable to vehicle
#leaving us with 4 categories [person, vehicle, two-wheeled, dilemma-zone]
#treating only dilemma-zone as iscrowd
#filtering dilemma_zone from class ClassBalancedDataset
#modifying self.CLASSES: [person, vehicle, two-wheeled]
#modifyed num_classes: 3
################################################################

checkpoint_config:
  interval: 1

custom_hooks:
  - type: NumClassCheckHook

dist_params:
  backend: nccl

log_level: INFO

load_from: ~
resume_from: ~
categories: !!python/tuple [person, vehicle, two-wheeled]

# disable opencv multithreading to avoid system being overloaded
opencv_num_threads: 0
# set multiprocess start method as `fork` to speed up the training
mp_start_method: fork

work_dir: ~
workflow: [!!python/tuple [train, 1], !!python/tuple [val, 1]]  # 1 epoch for training and 1 epoch for validation

log_config:
    interval: 50
    hooks:
      - type: TextLoggerHook
      - type: AllegroAiLLoggerHook

# model settings
model:
  type: YOLOV3
  backbone:
      type: Darknet
      depth: 53
      out_indices: !!python/tuple [3, 4, 5]
      init_cfg: ~
  neck:
    type: YOLOV3Neck
    num_scales: 3
    in_channels: [1024, 512, 256]
    out_channels: [512, 256, 128]
  bbox_head:
    type: YOLOV3Head
    num_classes: 3
    in_channels: [512, 256, 128]
    out_channels: [1024, 512, 256]
    anchor_generator:
      type: YOLOAnchorGenerator
      base_sizes:
        - [ !!python/tuple [ 31, 67 ], !!python/tuple [ 92, 47 ], !!python/tuple [ 97, 175 ] ]
        - [ !!python/tuple [ 30, 21 ], !!python/tuple [ 22, 48 ], !!python/tuple [ 53, 30 ] ]
        - [ !!python/tuple [ 17, 14 ], !!python/tuple [ 12, 26 ], !!python/tuple [ 16, 37 ] ]
      strides: [32, 16, 8]
    bbox_coder:
      type: YOLOBBoxCoder
    featmap_strides: [32, 16, 8]
    loss_cls:
      type: CrossEntropyLoss
      use_sigmoid: True
      class_weight: ~
      loss_weight: 1.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_conf:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 1.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_xy:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 2.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_wh:
      type: MSELoss
      loss_weight: 2.0
      reduction: sum
  train_cfg:
    assigner:
      type: GridAssigner
      pos_iou_thr: 0.5
      neg_iou_thr: 0.5
      min_pos_iou: 0
  test_cfg:
    nms_pre: 1000
    min_bbox_size: 0
    score_thr: 0.05
    conf_thr: 0.005
    nms:
      type: nms
      iou_threshold: 0.45
    max_per_img: 100

data:
  samples_per_gpu: 4
  workers_per_gpu: 4
  train:
    type: ~ #ClassBalancedDataset  # 'RepeatDataset',  # use RepeatDataset to speed up training
    oversample_thr: ~ #0.5  # number of minor category annotations / total number of images # times: 1,
    dataset:
      type: AllegroDataset
      CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
      filter_empty_gt: True
      remote:
        s3_root_dir: ~
        skip_local_run: False
        queue_name: scaler-styletransfer-g2g-rgbmwir
        prefetch: True
        url: ann_file_train.json
      args:
        generate_overfit: ~
        read_from_file:
          read: True
          path_name: ann_file_train.json
        to_serialize:
          save: True
          path_name: ~
        max_frame_size: 32
        filter_empty_gt: True
        data_root: '.'
        workflow: ~
      dataview_cfg:
        queries:
          dataset_name: Style_Transfer
          version_name: version_2_mwir_train
          weight: 1
        ignore_region: [ dilemma_zone ]
        name: train
        max_num_frames: ~
        frame_type: mwir
        cat_mapping: {"*": {out_of_lable: vehicle}}
        special_cat_mapping:
          ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
          ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
          negative: { "*": ~ }
        predefined_label_enums: ~
      pipeline:
        - type: LoadImageFromFile
          to_float32: False # if False the image returned is uint8 otherwise float32
          color_type: color # [color, grayscale, unchanged]
          channel_order: bgr  # if 'grayscale' channel_order doesn't matter
        - type: LoadAnnotations
          with_bbox: True
        - type: Albu
          transforms:
            - type: InvertImg
              p: 0.8
            - type: ShiftScaleRotate
              shift_limit: 0.0625
              scale_limit: 0.2
              rotate_limit: 20
              interpolation: 1
              border_mode: 1
              p: 1.0
            - type: RandomBrightnessContrast
              brightness_limit: [ 0.05, 0.15 ]
              contrast_limit: [ 0.05, 0.15 ]
              p: 0.5
            - type: Affine
              scale: 0.
              rotate: 0.
              translate_px: 0.
              shear: [ -20, 20 ]
              p: 0.8
            - type: Perspective
              scale: 0.2
              p: 0.5
            - type: GaussNoise
              mean: 0
              var_limit: !!python/tuple [ 10.0, 50.0 ]
              per_channel: True
              p: 0.5
            - type: HorizontalFlip
              p: 0.5
          bbox_params:
              type: BboxParams
              format: pascal_voc
              label_fields: [gt_labels]
              min_visibility: 0.0
              filter_lost_elements: True
          keymap: {'img': image, 'gt_bboxes': bboxes }
          update_pad_shape: False
          skip_img_without_anno: True
        - type: MinIoURandomCrop
          min_ious: !!python/tuple [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
          min_crop_size: 0.3
        - type: Resize
          img_scale:
            - !!python/tuple [320, 256]
            - !!python/tuple [640, 512]
          multiscale_mode: range
          keep_ratio: True
        - type: RandomFlip
          flip_ratio: 0.5
        - type: Normalize
          mean: [ 125.801, 125.801, 125.801 ]
          std: [ 59.555, 59.555, 59.555 ]
          to_rgb: False
        - type: Pad
          size_divisor: 32
        - type: DefaultFormatBundle
        - type: Collect
          keys:
            - img
            - gt_bboxes
            - gt_labels
  val:
    type: AllegroDataset
    CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
    remote:
      s3_root_dir: ~
      skip_local_run: False
      queue_name: scaler-styletransfer-g2g-rgbmwir
      prefetch: True
      url: ann_file_val.json
    args:
      generate_overfit: ~
      read_from_file:
        read: True
        path_name: ann_file_val.json
      to_serialize:
        save: True
        path_name: ann_file_val.json
      max_frame_size: 32
      filter_empty_gt: True
      data_root: '.'
      workflow: ~
    dataview_cfg:
      queries:
        dataset_name: Style_Transfer
        version_name: version_2_mwir_val
        weight: 1
      name: val
      ignore_region: [ dilemma_zone ]
      max_num_frames: ~
      frame_type: mwir
      cat_mapping: {"*": {out_of_lable: vehicle}} # Changing name of class as defined in the dataset to fit your models categories
      special_cat_mapping:
        ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
        ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
        negative: { "*": ~ }
      predefined_label_enums: ~
    pipeline:
      - type: LoadImageFromFile
        color_type: color
      - type: MultiScaleFlipAug
        img_scale: !!python/tuple [640, 512]
        flip: False
        transforms:
          - type: Resize
            keep_ratio: True
          - type: RandomFlip
          - type: Normalize
            mean: [ 125.882, 125.882, 125.882 ]
            std: [ 59.887, 59.887, 59.887 ]
            to_rgb: False
          - type: Pad
            size_divisor: 32
          - type: ImageToTensor
            keys:
              - img
          - type: Collect
            keys:
              - img
  test:
      type: AllegroDataset
      CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
      remote:
        s3_root_dir: ~
        skip_local_run: False
        queue_name: scaler-styletransfer-g2g-rgbmwir
        prefetch: True
        url: ann_file_val.json
      args:
        read_from_file:
          read: True
          path_name: ann_file_val.json
        to_serialize:
          save: False
          path_name: ann_file_val_clean.json
        max_frame_size: 32
        filter_empty_gt: True
        data_root: '.'
        workflow: ~
      dataview_cfg:
        queries:
          dataset_name: Style_Transfer
          version_name: version_2_mwir_val
          weight: 1
        name: val
        max_num_frames: ~
        frame_type: mwir
        cat_mapping: {"*": {out_of_lable: vehicle}} # Changing name of class as defined in the dataset to fit your models categories
        special_cat_mapping:
          ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
          ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
          negative: { "*": ~ }
        predefined_label_enums: ~
      pipeline:
        - type: LoadImageFromFile
          color_type: color
        - type: MultiScaleFlipAug
          img_scale: !!python/tuple [640, 512]
          flip: False
          transforms:
            - type: Resize
              keep_ratio: True
            - type: RandomFlip
            - type: Normalize
              mean: [ 125.882, 125.882, 125.882 ]
              std: [ 59.887, 59.887, 59.887 ]
              to_rgb: False
            - type: Pad
              size_divisor: 32
            - type: ImageToTensor
              keys:
                - img
            - type: Collect
              keys:
                - img
optimizer:
  type: SGD
  lr: 0.001 # start
  momentum: 0.9
  weight_decay: 0.0005

#optimizer:
#  type: AdamW
#  lr: 0.0001
#  weight_decay: 0.05
#  paramwise_cfg:
#    norm_decay_mult: 0.
#    bypass_duplicate: True

optimizer_config:
  grad_clip:
    max_norm: 35
    norm_type: 2

lr_config:
    policy: CosineAnnealing
    warmup: linear
    warmup_iters: 4000
    warmup_ratio: 0.1
    min_lr_ratio: 1.e-5
    warmup_by_epoch: False

#lr_config:
#  policy: step
#  warmup: linear
#  warmup_iters: 4000
#  warmup_ratio: 0.0001
#  step: [24, 28]

# runtime settings
runner:
  type: EpochBasedRunner
  max_epochs: 80

# evaluate the model every "interval=1" epochs.
evaluation:
  interval: 1
  save_best: bbox_mAP
  rule: greater
  metric:
   - bbox
  iou_thrs: ~
  metric_items: ~
  classwise: True

find_unused_parameters: True
auto_resume: False
gpu_ids:
  - 1

auto_scale_lr:
  enable: False
  base_batch_size: 64
