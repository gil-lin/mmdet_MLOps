
###############################################################
#Config Description:
#map : out_of_lable to vehicle
#leaving us with 4 categories [person, vehicle, two-wheeled, dilemma-zone]
#treating only dilemma-zone as iscrowd
#filtering dilemma_zone from class ClassBalancedDataset
#modifying self.CLASSES: [person, vehicle, two-wheeled]
#modifyed num_classes: 3
################################################################

checkpoint_config:
  interval: 1

custom_hooks:
  - type: NumClassCheckHook

dist_params:
  backend: nccl

log_level: INFO

load_from: ~
resume_from: ~
categories: !!python/tuple [person, vehicle, two-wheeled]

# disable opencv multithreading to avoid system being overloaded
opencv_num_threads: 0
# set multiprocess start method as `fork` to speed up the training
mp_start_method: fork

work_dir: ~
workflow: [!!python/tuple [train, 1], !!python/tuple [val, 1]]  # 1 epoch for training and 1 epoch for validation

log_config:
    interval: 50
    hooks:
      - type: TextLoggerHook
      - type: AllegroAiLLoggerHook

# model settings
model:
  type: YOLOV3
  backbone:
      type: MobileNetV2
      out_indices: !!python/tuple [2, 4, 6]
      act_cfg:
          type: LeakyReLU
          negative_slope: 0.1
      init_cfg:
        type: Pretrained
        checkpoint: open-mmlab://mmdet/mobilenet_v2  # train from scratch otherwise use default yolov3 config
  neck:
    type: YOLOV3Neck
    num_scales: 3
    in_channels: [320, 96, 32]
    out_channels: [96, 96, 96]
  bbox_head:
    type: YOLOV3Head
    num_classes: 3
    in_channels: [96, 96, 96]
    out_channels: [96, 96, 96]
    anchor_generator:
      type: YOLOAnchorGenerator
      base_sizes:
        - [!!python/tuple [29, 70], !!python/tuple [94, 46], !!python/tuple [60, 122]]
        - [!!python/tuple [25, 17], !!python/tuple [19, 43], !!python/tuple [50, 29]]
        - [!!python/tuple [6, 10], !!python/tuple [9, 19], !!python/tuple [12, 30]]
      strides: [32, 16, 8]
    bbox_coder:
      type: YOLOBBoxCoder
    featmap_strides: [32, 16, 8]
    loss_cls:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 1.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_conf:
      type: CrossEntropyLoss
      class_weight: ~
      use_sigmoid: True
      loss_weight: 1.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_xy:
      type: CrossEntropyLoss
      use_sigmoid: True
      loss_weight: 2.0
      reduction: sum
      avg_non_ignore: ~
      ignore_index: ~
    loss_wh:
      type: MSELoss
      loss_weight: 2.0
      reduction: sum
  train_cfg:
    assigner:
      type: GridAssigner
      pos_iou_thr: 0.5
      neg_iou_thr: 0.5
      min_pos_iou: 0
  test_cfg:
    nms_pre: 1000
    min_bbox_size: 0
    score_thr: 0.05
    conf_thr: 0.005
    nms:
      type: nms
      iou_threshold: 0.45
    max_per_img: 100

data:
  samples_per_gpu: 4
  workers_per_gpu: 4
  train:
    type: ~ #ClassBalancedDataset  # 'RepeatDataset',  # use RepeatDataset to speed up training
    oversample_thr: ~ #0.5  # number of minor category annotations / total number of images # times: 1,
    dataset:
      type: AllegroDataset
      CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
      filter_empty_gt: True
      remote:
        s3_root_dir: ~
        skip_local_run: False
        queue_name: scaler-styletransfer-g2g-rgbmwir
        prefetch: True
        url: ann_file_train.json
      args:
        generate_overfit: ~
        read_from_file:
          read: True
          path_name: ann_file_train.json
        to_serialize:
          save: True
          path_name: ~
        max_frame_size: 32
        filter_empty_gt: True
        data_root: '.'
        workflow: ~
      dataview_cfg:
        queries:
          dataset_name: Style_Transfer
          version_name: version_2_rgb_train
          weight: 1
        ignore_region: [ dilemma_zone ]
        name: train
        max_num_frames: ~
        frame_type: rgb
        cat_mapping: {"*": {out_of_lable: vehicle}}
        special_cat_mapping:
          ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
          ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
          negative: { "*": ~ }
        predefined_label_enums: ~
      pipeline:
        - type: LoadImageFromFile
          to_float32: False # if False the image returned is uint8 otherwise float32
          color_type: color # [color, grayscale, unchanged]
          channel_order: bgr  # if 'grayscale' channel_order doesn't matter
        - type: LoadAnnotations
          with_bbox: True
        - type: Albu
          transforms:
            - type: ShiftScaleRotate
              shift_limit: 0.0625
              scale_limit: 0.0
              rotate_limit: 20
              interpolation: 1
              border_mode: 1
              p: 1.0
            - type: RandomBrightnessContrast
              brightness_limit: [0.05, 0.2]
              contrast_limit: [0.05, 0.2]
              p: 0.5
            - type: ChannelShuffle
              p: 0.5
#            - type: OneOf
#              transforms:
#                - type: Blur
#                  blur_limit: 3
#                  p: 0.5
#                - type: MedianBlur
#                  blur_limit: 3
#                  p: 0.5
#              p: 0.5
#            - type: GaussNoise
#              mean: 0
#              var_limit: !!python/tuple [ 10.0, 50.0 ]
#              per_channel: True
#              p: 0.5
            - type: HueSaturationValue
              hue_shift_limit: 10
              sat_shift_limit: 10
              val_shift_limit: 10
              p: 0.5
#            - type: RGBShift
#              r_shift_limit: 10
#              g_shift_limit: 10
#              b_shift_limit: 10
#              p: 0.5
#            - type: RandomGamma
#              gamma_limit: !!python/tuple [ 80, 120 ]
#              p: 0.5
            - type: Affine
              scale: 0.
              rotate: 0.
              translate_px: 0.
              shear: [-20, 20]
              p: 0.8
            - type: Perspective
              scale: 0.2
              p: 0.8
            - type: HorizontalFlip
              p: 0.5
          bbox_params:
              type: BboxParams
              format: pascal_voc
              label_fields: [gt_labels]
              min_area: 100
              min_visibility: 0.3
              filter_lost_elements: True
          keymap: {'img': image, 'gt_bboxes': bboxes }
          update_pad_shape: False
          skip_img_without_anno: True
        - type: MinIoURandomCrop
          min_ious: !!python/tuple [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
          min_crop_size: 0.3
        - type: Resize
          img_scale:
            - !!python/tuple [384, 288]
            - !!python/tuple [768, 576]
          multiscale_mode: range
          keep_ratio: True
        - type: RandomFlip
          flip_ratio: 0.5
        - type: Normalize
          mean: [ 109.880, 113.804, 114.335 ]
          std: [ 48.654, 50.899, 53.007 ]
          to_rgb: True
        - type: Pad
          size_divisor: 32
        - type: DefaultFormatBundle
        - type: Collect
          keys:
            - img
            - gt_bboxes
            - gt_labels
  val:
    type: AllegroDataset
    CLASSES: !!python/tuple [person, vehicle, two-wheeled, out_of_lable, dilemma_zone]
    remote:
      s3_root_dir: ~
      skip_local_run: False
      queue_name: scaler-styletransfer-g2g-rgbmwir
      prefetch: True
      url: ann_file_val.json
    args:
      generate_overfit: ~
      read_from_file:
        read: True
        path_name: ann_file_val.json
      to_serialize:
        save: False
        path_name: ~
      max_frame_size: 32
      filter_empty_gt: True
      data_root: '.'
      workflow: ~
    dataview_cfg:
      queries:
        dataset_name: Style_Transfer
        version_name: version_2_rgb_val
        weight: 1
      name: val
      ignore_region: [ dilemma_zone ]
      max_num_frames: ~
      frame_type: rgb
      cat_mapping: { "*": { out_of_lable: vehicle } } # Changing name of class as defined in the dataset to fit your models categories
      special_cat_mapping:
        ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
        ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
        negative: { "*": ~ }
      predefined_label_enums: ~
    pipeline:
      - type: LoadImageFromFile
        color_type: color
      - type: MultiScaleFlipAug
        img_scale: !!python/tuple [ 768, 576 ]
        flip: False
        transforms:
          - type: Resize
            keep_ratio: True
          - type: RandomFlip
          - type: Normalize
            mean: [ 110.675, 113.167, 113.311 ]
            std: [ 47.832, 49.947, 51.754 ]
            to_rgb: True
          - type: Pad
            size_divisor: 32
          - type: ImageToTensor
            keys:
              - img
          - type: Collect
            keys:
              - img
  test:
    type: AllegroDataset
    CLASSES: !!python/tuple [ person, vehicle, two-wheeled, out_of_lable, dilemma_zone ]
    remote:
      s3_root_dir: ~
      skip_local_run: False
      queue_name: scaler-styletransfer-g2g-rgbmwir
      prefetch: True
      url: ann_file_val.json
    args:
      read_from_file:
        read: True
        path_name: ann_file_val.json
      to_serialize:
        save: False
        path_name: ann_file_val.json
      max_frame_size: 32
      filter_empty_gt: True
      data_root: '.'
      workflow: ~
    dataview_cfg:
      queries:
        dataset_name: Style_Transfer
        version_name: version_2_rgb_val
        weight: 1
      ignore_region: [ dilemma_zone ]
      name: val
      max_num_frames: ~
      frame_type: rgb
      cat_mapping: { "*": { out_of_lable: vehicle } } # Changing name of class as defined in the dataset to fit your models categories
      special_cat_mapping:
        ignore: { "*": ~ }  # Treat a gt bb as neither positive nor negative
        ignore_region: { "*": ~ }  #{"*": 'dilemma_zone'},  # Any prediction inside should be regarded as ignored bb
        negative: { "*": ~ }
      predefined_label_enums: ~
    pipeline:
      - type: LoadImageFromFile
        color_type: color
      - type: MultiScaleFlipAug
        img_scale: !!python/tuple [ 768, 576 ]
        flip: False
        transforms:
          - type: Resize
            keep_ratio: True
          - type: RandomFlip
          - type: Normalize
            mean: [ 110.675, 113.167, 113.311 ]
            std: [ 48.654, 50.899, 53.007 ]
            to_rgb: True
          - type: Pad
            size_divisor: 32
          - type: ImageToTensor
            keys:
              - img
          - type: Collect
            keys:
              - img


optimizer:
  type: SGD
  lr: 0.001 # start
  momentum: 0.9
  weight_decay: 0.0005

#optimizer:
#  type: AdamW
#  lr: 0.0001
#  weight_decay: 0.05
#  paramwise_cfg:
#    norm_decay_mult: 0.
#    bypass_duplicate: True

optimizer_config:
  grad_clip:
    max_norm: 35
    norm_type: 2

lr_config:
    policy: CosineAnnealing
    warmup: linear
    warmup_iters: 4000
    warmup_ratio: 0.1
    min_lr_ratio: 1.e-5
    warmup_by_epoch: False

#lr_config:
#  policy: step
#  warmup: linear
#  warmup_iters: 4000
#  warmup_ratio: 0.0001
#  step: [24, 28]

# runtime settings
runner:
  type: EpochBasedRunner
  max_epochs: 80

# evaluate the model every "interval=1" epochs.
evaluation:
  interval: 1
  save_best: bbox_mAP
  rule: greater
  metric:
   - bbox
  classwise: True

find_unused_parameters: True
auto_resume: False
gpu_ids:
  - 1

auto_scale_lr:
  enable: False
  base_batch_size: 64

# 'Pretrained', checkpoint='open-mmlab://mmdet/mobilenet_v2')),